{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-22T03:41:22.289573Z",
     "start_time": "2024-11-22T03:41:22.273630Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 初始化张量",
   "id": "ba21a16dd47ad0c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:00:48.005334Z",
     "start_time": "2024-11-20T12:00:47.966378Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 直接用数据创建，数据类型自动推断\n",
    "data = [[4, 6, 7], [2, 7, 4]]\n",
    "t1_data = torch.tensor(data,\n",
    "                       device=\"cuda\",\n",
    "                       requires_grad=True)  # 该属性会记录梯度值信息，如果不设置，反向传播会没有梯度\n",
    "print(t1_data)"
   ],
   "id": "2c5861fe0b02853",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 6, 7],\n",
      "        [2, 7, 4]])\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:09:20.661145Z",
     "start_time": "2024-11-20T12:09:20.637874Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从numpy数组创建\n",
    "np_data = np.array(data)\n",
    "t1_np=torch.from_numpy(np_data)\n",
    "print(t1_np)"
   ],
   "id": "4e2ced78fcc8c2d2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 6, 7],\n",
      "        [2, 7, 4]])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:45:14.408179Z",
     "start_time": "2024-11-20T12:45:14.390226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 从另一个张量创建\n",
    "t1_ones=torch.ones_like(t1_np)  # 保留源数据的属性(形状和数据类型),值变为1\n",
    "print(t1_ones)\n",
    "t1_rand=torch.rand_like(t1_np,dtype=torch.float)  # 会覆盖之前的数据，形状不变，数据变成0到1之间的浮点型\n",
    "print(t1_rand)"
   ],
   "id": "149380b96db1dec4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]])\n",
      "tensor([[0.4887, 0.1744, 0.8066],\n",
      "        [0.9912, 0.8698, 0.4745]])\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T12:56:27.447806Z",
     "start_time": "2024-11-20T12:56:27.436833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 创建随机值或者常量值，可通过shape指定形状，shape需要是一个数组\n",
    "shape=(3,4)\n",
    "t_rand=torch.rand(shape)\n",
    "t_ones=torch.ones(shape)\n",
    "t_zeros=torch.zeros(shape)\n",
    "\n",
    "print(t_rand)\n",
    "print(t_ones)\n",
    "print(t_zeros)"
   ],
   "id": "12f96dfa98625d1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7893, 0.8119, 0.5694, 0.8201],\n",
      "        [0.2856, 0.8608, 0.3524, 0.0169],\n",
      "        [0.9965, 0.7266, 0.7276, 0.9687]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:15:20.585346Z",
     "start_time": "2024-11-20T13:15:20.552046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 其他创建方法\n",
    "# 均匀分布\n",
    "t1=torch.rand(5,5)\n",
    "# 标准正态分布\n",
    "t2=torch.randn(5,5)\n",
    "# 离散正态分布\n",
    "t3=torch.normal(mean=0.0,std=1.0,size=(5,5))\n",
    "# 线性间隔向量(返回一维张量，包含start和end上均匀间隔的step个点)\n",
    "t4=torch.linspace(start=-1,end=10,steps=10)\n",
    "print(f\"均匀分布{t1}\\n标准正态分布{t2}\\n离散正态分布{t3}\\n线性间隔{t4}\")"
   ],
   "id": "daf074ad875b739a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "均匀分布tensor([[0.3207, 0.2002, 0.3376, 0.5144, 0.6966],\n",
      "        [0.7474, 0.1974, 0.9884, 0.6000, 0.3422],\n",
      "        [0.7919, 0.9962, 0.7407, 0.1317, 0.7073],\n",
      "        [0.9457, 0.4631, 0.6441, 0.1591, 0.4266],\n",
      "        [0.2363, 0.0873, 0.6378, 0.4015, 0.0761]])\n",
      "标准正态分布tensor([[-0.2906, -0.8907, -0.7970,  0.1803, -1.4908],\n",
      "        [-0.9400,  1.5824, -1.3060,  0.3925,  0.3021],\n",
      "        [ 0.1791,  0.6606,  0.6363, -0.9073, -1.3009],\n",
      "        [ 0.7817,  0.6059, -0.8554,  0.8660,  1.0193],\n",
      "        [-0.3810,  0.6428,  0.1713, -0.0266,  0.1199]])\n",
      "离散正态分布tensor([[-0.1575, -0.6616,  1.0440,  0.9712, -0.2390],\n",
      "        [-1.4145, -1.0902, -0.0329,  0.1306,  1.3077],\n",
      "        [-1.6729, -0.8652, -0.8887, -1.2437, -1.1711],\n",
      "        [-0.7586,  0.0781, -0.0967, -0.0669,  0.7740],\n",
      "        [ 0.1881, -1.5005, -1.6697, -0.7664,  2.0282]])\n",
      "线性间隔tensor([-1.0000,  0.2222,  1.4444,  2.6667,  3.8889,  5.1111,  6.3333,  7.5556,\n",
      "         8.7778, 10.0000])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:24:41.654567Z",
     "start_time": "2024-11-20T13:24:41.635619Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 张量的属性\n",
    "print(\"张量的形状: \",t1.shape)  # 反回一个torch.Size对象\n",
    "print(\"张量的数据类型: \",t1.dtype)\n",
    "print(\"张量的存储设备: \",t1.device)\n",
    "print(\"张量的尺寸大小: \",t1.size())  # 同t1.shape,但是这是方法需要带括号\n"
   ],
   "id": "75acae3656816212",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "张量的形状:  torch.Size([5, 5])\n",
      "张量的数据类型:  torch.float32\n",
      "张量的存储设备:  cpu\n",
      "张量的尺寸大小:  torch.Size([5, 5])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 张量运算\n",
    "\n",
    "张量默认创建在cpu，一般在gpu运行快，可以通过.to(\"cuda\")移动\n",
    "\n",
    "**注意:** 跨设备移动大张量在时间和内存方面成本都很高 "
   ],
   "id": "16fefc5666d523e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:47:32.422904Z",
     "start_time": "2024-11-20T13:47:29.455544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor = torch.tensor(4)\n",
    "if torch.cuda.is_available():  # 有cuda就返回true\n",
    "    tensor = tensor.to('cuda')\n",
    "print(tensor)"
   ],
   "id": "a4f1738bf8209aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4, device='cuda:0')\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T13:56:28.662331Z",
     "start_time": "2024-11-20T13:56:28.652359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# tensor索引和切片高度类似numpy\n",
    "torch.manual_seed(0)  # 设置随机种子\n",
    "tensor=torch.rand(4,4)\n",
    "print(tensor)\n",
    "print('第一行',tensor[0])\n",
    "print('第一列',tensor[:,0])\n",
    "print('最后一列',tensor[...,-1])\n"
   ],
   "id": "2b3b7d1e28add660",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4963, 0.7682, 0.0885, 0.1320],\n",
      "        [0.3074, 0.6341, 0.4901, 0.8964],\n",
      "        [0.4556, 0.6323, 0.3489, 0.4017],\n",
      "        [0.0223, 0.1689, 0.2939, 0.5185]])\n",
      "第一行 tensor([0.4963, 0.7682, 0.0885, 0.1320])\n",
      "第一列 tensor([0.4963, 0.3074, 0.4556, 0.0223])\n",
      "最后一列 tensor([0.1320, 0.8964, 0.4017, 0.5185])\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:00:28.412469Z",
     "start_time": "2024-11-20T14:00:28.392523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 拼接\n",
    "t1=torch.ones(3,4)\n",
    "t2=torch.zeros(3,4)\n",
    "t3=torch.cat([t1,t2],dim=1)\n",
    "t4=torch.cat([t1,t2])\n",
    "print(t3)\n",
    "print(t4)"
   ],
   "id": "dafe8c2ee60dcbd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T09:59:44.631334Z",
     "start_time": "2024-11-21T09:59:44.575485Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 算术运算\n",
    "# 点积运算\n",
    "tensor=torch.tensor([[1.,2.,3.],[4.,5.,6.]])\n",
    "t1=tensor@tensor.T\n",
    "t2=tensor.matmul(tensor.T)\n",
    "t3=torch.rand_like(tensor)\n",
    "torch.matmul(tensor,tensor.T,out=t3)  # 这种输出形状不匹配会报警告，提示以后将不支持\n",
    "print(t1,t2,t3)"
   ],
   "id": "522089774cd884f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[14., 32.],\n",
      "        [32., 77.]]) tensor([[14., 32.],\n",
      "        [32., 77.]]) tensor([[14., 32.],\n",
      "        [32., 77.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8728\\2232807614.py:7: UserWarning: An output with one or more elements was resized since it had shape [2, 3], which does not match the required output shape [2, 2]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\Resize.cpp:35.)\n",
      "  torch.matmul(tensor,tensor.T,out=t3)  # 这种输出形状不匹配会报警告，提示以后将不支持\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T14:12:05.724069Z",
     "start_time": "2024-11-20T14:12:05.709108Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 可以用item将单元素张量转换为python数\n",
    "t_sum=tensor.sum()\n",
    "i=t_sum.item()\n",
    "print(i,type(i))"
   ],
   "id": "f14154556f99a105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0 <class 'float'>\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T10:00:05.020578Z",
     "start_time": "2024-11-21T10:00:04.998637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Inplace操作\n",
    "#把计算结果存储到当前操作数中的操作就称为就地操作。含义和pandas中inPlace参数的含义一样。pytorch中，这些操作是由带有下划线_后缀的函数表示。例如：x.copy_(y),x.t_(), 将改变x自身的值。\n",
    "# In-place操作虽然节省了一部分内存，但在计算导数时可能会出现问题，因为它会立即丢失历史记录。因此，不鼓励使用它们。\n",
    "print(tensor)\n",
    "tensor.add_(5)  # 加法，广播\n",
    "print(tensor)"
   ],
   "id": "17547c91db5e7348",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### tensor 与 numpy之间的转换\n",
    "\n",
    "CPU 和 NumPy 数组上的张量共享底层内存位置，所以改变一个另一个也会变。"
   ],
   "id": "11186364e34b343f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T03:55:57.905231Z",
     "start_time": "2024-11-22T03:55:57.832428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 张量到numpy数组\n",
    "t = torch.ones(5)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")\n",
    "t.add_(1)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "id": "22d356993ab4646c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T03:57:43.384197Z",
     "start_time": "2024-11-22T03:57:43.362256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Numpy数组到张量\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "np.add(n, 1, out=n)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ],
   "id": "dd59febdd574bbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2c9435b1e4e002c4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
